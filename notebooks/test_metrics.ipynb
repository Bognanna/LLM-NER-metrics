{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc69364f",
   "metadata": {},
   "source": [
    "## Approach 1: Measure quality of generated by LLM entities with their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527c21b",
   "metadata": {},
   "source": [
    "\n",
    "~~For each pairwise matching between generated entities and gold entities the sum of cosinus similarities between their embeddings is calculated. Similarity for each entity without a pair is -1. As a metric, the maximal sum of similarities is taken and divided by max(number_of_generated_entites, number_of_gold_entities).~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff689f89",
   "metadata": {},
   "source": [
    "### Metric 1.1: Maximal average cosinus similarity of embeddings\n",
    "The metric consists in fact of several metrics:\n",
    "\n",
    "1) \n",
    "- a) Maximal average cosinus similarity of embeddings (brute force)\n",
    "For each pairwise matching between generated entities and gold entities the sum of cosinus similarities between their embeddings is calculated. As a metric, the max sum of similarities is taken and divided by min(number_of_generated_entites, number_of_gold_entities). \n",
    "\n",
    "- b) Average cosinus similarity of embeddings (greedy)\n",
    "For greedy matching between generated entities and gold entities the sum of cosinus similarities between their embeddings is calculated. The sum is divided by min(number_of_generated_entites, number_of_gold_entities).\n",
    "\n",
    "2) Found entities measure\n",
    "- | generated entities | / | gold entities | - 1\n",
    "- <-1; 0) - LLM did not found all entities\n",
    "- 0 - LLM found all entities\n",
    "- (0; +oo) - LLM halucynated some entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c485dd",
   "metadata": {},
   "source": [
    "#### Load benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('..\\\\data\\\\external\\\\benchmark\\\\approach_1_benchmark.json') as f:\n",
    "    benchmark_dataset = json.load(f)\n",
    "    benchmark_dataset = benchmark_dataset['Data']\n",
    "\n",
    "sentences = []\n",
    "perfect = []\n",
    "good = []\n",
    "ok = []\n",
    "\n",
    "for element in benchmark_dataset:\n",
    "    sentences.append(element['Sentence'])\n",
    "    perfect.append(element['Perfect'])\n",
    "    good.append(element['Good'])\n",
    "    ok.append(element['Ok'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e87f80",
   "metadata": {},
   "source": [
    "#### Get text embeddings using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30c5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "EMBED_MODEL = 'nomic-embed-text'\n",
    "\n",
    "def get_text_embedding_using_ollama(text:str):\n",
    "    \n",
    "    if text:\n",
    "\n",
    "        response = ollama.embed(\n",
    "            model=EMBED_MODEL,\n",
    "            input=text,\n",
    "        )\n",
    "\n",
    "        return response[\"embeddings\"]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1e384",
   "metadata": {},
   "source": [
    "#### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d395435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    v1 = np.squeeze(np.asarray(v1))\n",
    "    v2 = np.squeeze(np.asarray(v2))\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67deb7",
   "metadata": {},
   "source": [
    "#### Test metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064a4aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metric(metric_fun, sentences, perfect, good, ok, verbose = False):\n",
    "\n",
    "    n_passed = 0\n",
    "    n_failed = 0\n",
    "\n",
    "    for s, p, g, o in zip(sentences, perfect, good, ok):\n",
    "\n",
    "        s1 = metric_fun(p, p)\n",
    "        s2 = metric_fun(p, g)\n",
    "        s3 = metric_fun(p, o)\n",
    "\n",
    "        # if verbose: print(f'{p}\\t{g}\\t{o}')\n",
    "        if s1 >= s2 >= s3:\n",
    "            # if verbose: print(f'TEST PASSED\\t{s1}\\t{s2}\\t{s3}\\n')\n",
    "            n_passed += 1\n",
    "        else:\n",
    "            if verbose: print(f'{p}\\t{g}\\t{o}')\n",
    "            if verbose: print(f'TEST FAILED\\t{s1}\\t{s2}\\t{s3}\\n')\n",
    "            n_failed += 1\n",
    "\n",
    "    return n_passed, n_failed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c274eb74",
   "metadata": {},
   "source": [
    "#### Tests on sample sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c935482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of healthy_1 & healthy_1: 1.0000000000000002\n",
      "Cosine similarity of healthy_1 & sick_1: 0.8546183276069252\n",
      "Cosine similarity of healthy_1 & sick_2: 0.5154896673187178\n",
      "Cosine similarity of healthy_1 & unrelated_1: 0.452276206883047\n",
      "Cosine similarity of sick_1 & sick_1: 1.0\n",
      "Cosine similarity of sick_1 & sick_2: 0.5267311993602283\n",
      "Cosine similarity of sick_1 & unrelated_1: 0.4003778194513241\n",
      "Cosine similarity of sick_2 & sick_2: 0.9999999999999999\n",
      "Cosine similarity of sick_2 & unrelated_1: 0.45925846382791224\n",
      "Cosine similarity of unrelated_1 & unrelated_1: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "healthy_1 = \"Healthy.\"\n",
    "sick_1 = \"Not healthy.\"\n",
    "sick_2 = \"Ill.\"\n",
    "unrelated_1 = \"Cat.\"\n",
    "\n",
    "embed_healthy_1 = get_text_embedding_using_ollama(healthy_1)\n",
    "embed_sick_1 = get_text_embedding_using_ollama(sick_1)\n",
    "embed_sick_2 = get_text_embedding_using_ollama(sick_2)\n",
    "embed_unrelated_1 = get_text_embedding_using_ollama(unrelated_1)\n",
    "\n",
    "print(f\"Cosine similarity of healthy_1 & healthy_1: {cosine_similarity(embed_healthy_1, embed_healthy_1)}\")\n",
    "print(f\"Cosine similarity of healthy_1 & sick_1: {cosine_similarity(embed_healthy_1, embed_sick_1)}\")\n",
    "print(f\"Cosine similarity of healthy_1 & sick_2: {cosine_similarity(embed_healthy_1, embed_sick_2)}\")\n",
    "print(f\"Cosine similarity of healthy_1 & unrelated_1: {cosine_similarity(embed_healthy_1, embed_unrelated_1)}\")\n",
    "\n",
    "print(f\"Cosine similarity of sick_1 & sick_1: {cosine_similarity(embed_sick_1, embed_sick_1)}\")\n",
    "print(f\"Cosine similarity of sick_1 & sick_2: {cosine_similarity(embed_sick_1, embed_sick_2)}\")\n",
    "print(f\"Cosine similarity of sick_1 & unrelated_1: {cosine_similarity(embed_sick_1, embed_unrelated_1)}\")\n",
    "\n",
    "print(f\"Cosine similarity of sick_2 & sick_2: {cosine_similarity(embed_sick_2, embed_sick_2)}\")\n",
    "print(f\"Cosine similarity of sick_2 & unrelated_1: {cosine_similarity(embed_sick_2, embed_unrelated_1)}\")\n",
    "\n",
    "print(f\"Cosine similarity of unrelated_1 & unrelated_1: {cosine_similarity(embed_unrelated_1, embed_unrelated_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of healthy_1 & healthy_1: 1.0000000000000002\n",
      "Cosine similarity of healthy_1 & sick_1: 0.8680167736583562\n",
      "Cosine similarity of healthy_1 & sick_2: 0.7767000617900933\n",
      "Cosine similarity of healthy_1 & unrelated_1: 0.42161666638300177\n",
      "Cosine similarity of sick_1 & sick_1: 1.0\n",
      "Cosine similarity of sick_1 & sick_2: 0.9112396526264309\n",
      "Cosine similarity of sick_1 & unrelated_1: 0.4267955805726447\n",
      "Cosine similarity of sick_2 & sick_2: 1.0000000000000002\n",
      "Cosine similarity of sick_2 & unrelated_1: 0.39593371671041494\n",
      "Cosine similarity of unrelated_1 & unrelated_1: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "healthy_1 = \"The patient is healthy and shows no signs of illness.\"\n",
    "sick_1 = \"The patient is not healthy and shows signs of illness.\"\n",
    "sick_2 = \"The patient is extremely sick and shows signs of multiple serious illnesses.\"\n",
    "unrelated_1 = \"The cat slept on the windowsill all afternoon.\"\n",
    "\n",
    "embed_healthy_1 = get_text_embedding_using_ollama(healthy_1)\n",
    "embed_sick_1 = get_text_embedding_using_ollama(sick_1)\n",
    "embed_sick_2 = get_text_embedding_using_ollama(sick_2)\n",
    "embed_unrelated_1 = get_text_embedding_using_ollama(unrelated_1)\n",
    "\n",
    "print(f\"Cosine similarity of healthy_1 & healthy_1: {cosine_similarity(embed_healthy_1, embed_healthy_1)}\")\n",
    "print(f\"Cosine similarity of healthy_1 & sick_1: {cosine_similarity(embed_healthy_1, embed_sick_1)}\")\n",
    "print(f\"Cosine similarity of healthy_1 & sick_2: {cosine_similarity(embed_healthy_1, embed_sick_2)}\")\n",
    "print(f\"Cosine similarity of healthy_1 & unrelated_1: {cosine_similarity(embed_healthy_1, embed_unrelated_1)}\")\n",
    "\n",
    "print(f\"Cosine similarity of sick_1 & sick_1: {cosine_similarity(embed_sick_1, embed_sick_1)}\")\n",
    "print(f\"Cosine similarity of sick_1 & sick_2: {cosine_similarity(embed_sick_1, embed_sick_2)}\")\n",
    "print(f\"Cosine similarity of sick_1 & unrelated_1: {cosine_similarity(embed_sick_1, embed_unrelated_1)}\")\n",
    "\n",
    "print(f\"Cosine similarity of sick_2 & sick_2: {cosine_similarity(embed_sick_2, embed_sick_2)}\")\n",
    "print(f\"Cosine similarity of sick_2 & unrelated_1: {cosine_similarity(embed_sick_2, embed_unrelated_1)}\")\n",
    "\n",
    "print(f\"Cosine similarity of unrelated_1 & unrelated_1: {cosine_similarity(embed_unrelated_1, embed_unrelated_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a8e58",
   "metadata": {},
   "source": [
    "#### 1.1.1.a Maximal average cosinus similarity of embeddings (brute force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ab38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "\n",
    "def max_avg_cos_similarity(generated_entities, golden_entities):\n",
    "\n",
    "    generated_entities = copy.copy(generated_entities)\n",
    "    golden_entities = copy.copy(golden_entities)\n",
    "\n",
    "    min_len = min(len(golden_entities), len(generated_entities))\n",
    "    max_len = max(len(golden_entities), len(generated_entities))\n",
    "    \n",
    "    # Fill list with padding, to obtain two lists of the same size\n",
    "    for n in range(len(golden_entities), max_len):\n",
    "        golden_entities.append(None)\n",
    "\n",
    "    for n in range(len(generated_entities), max_len):  \n",
    "        generated_entities.append(None)\n",
    "        \n",
    "    # Get text embeddings for each entity\n",
    "    golden_embeddings = [get_text_embedding_using_ollama(entity) for entity in golden_entities]\n",
    "    generated_embeddings = [get_text_embedding_using_ollama(entity) for entity in generated_entities]\n",
    "    \n",
    "\n",
    "    best_permutation = generated_entities\n",
    "    maximal_similarity = -1\n",
    "\n",
    "    for permutation in list(itertools.permutations(list(range(max_len)))):\n",
    "\n",
    "        sum_cosine_similarities = 0\n",
    "        permutated_generated_embeddings = [generated_embeddings[i] for i in permutation]\n",
    "\n",
    "        for golden_embedding, generated_embedding in zip(golden_embeddings, permutated_generated_embeddings):\n",
    "\n",
    "            if golden_embedding and generated_embedding:\n",
    "                sum_cosine_similarities += cosine_similarity(golden_embedding, generated_embedding)\n",
    "\n",
    "        if sum_cosine_similarities/min_len > maximal_similarity:\n",
    "            maximal_similarity = sum_cosine_similarities/min_len\n",
    "            best_permutation = [generated_entities[i] for i in permutation]\n",
    "\n",
    "    return maximal_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52cb0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['severe pain in the muscles in the shoulder area']\t['severe pain in the muscles']\t['severe pain in the muscles', 'severe pain in the shoulder area']\n",
      "TEST FAILED\t1.0\t0.8627380522048517\t0.9574064207803092\n",
      "\n",
      "['increased blood pressure', 'increased heart rate']\t['blood pressure', 'heart rate']\t['increased blood pressure and heart rate']\n",
      "TEST FAILED\t1.0\t0.8590391771065524\t0.9162281472371826\n",
      "\n",
      "['mild shortness of breath on exertion']\t['shortness of breath']\t['breath on exertion']\n",
      "TEST FAILED\t1.0000000000000002\t0.8685195001479415\t0.8846911153655715\n",
      "\n",
      "['left leg swelling', 'left leg redness']\t['leg swelling', 'redness']\t['leg swelling and redness']\n",
      "TEST FAILED\t1.0\t0.8519824239361447\t0.8553893403675195\n",
      "\n",
      "['upper abdominal pain', 'upper abdominal bloating']\t['abdominal pain', 'bloating']\t['abdominal pain and bloating']\n",
      "TEST FAILED\t1.0\t0.833672914990464\t0.8464600754327717\n",
      "\n",
      "['joint stiffness in the morning']\t['joint stiffness']\t['stiffness in morning']\n",
      "TEST FAILED\t1.0000000000000002\t0.8273280305572597\t0.925218796683792\n",
      "\n",
      "['difficulty swallowing', 'difficulty speaking']\t['swallowing', 'speaking difficulties']\t['difficulty swallowing and speaking']\n",
      "TEST FAILED\t1.0\t0.9241474738527136\t0.9305288462469052\n",
      "\n",
      "['high cholesterol', 'high triglycerides']\t['cholesterol', 'triglycerides']\t['high cholesterol and triglycerides']\n",
      "TEST FAILED\t1.0\t0.8933068880626787\t0.9077254993145528\n",
      "\n",
      "['elevated blood glucose levels']\t['blood glucose']\t['glucose levels elevated']\n",
      "TEST FAILED\t1.0\t0.8238225585259946\t0.9614886074059923\n",
      "\n",
      "['mild anemia', 'low hematocrit']\t['anemia', 'hematocrit']\t['mild anemia and low hematocrit']\n",
      "TEST FAILED\t1.0\t0.8773180779249135\t0.8809624535590347\n",
      "\n",
      "['hearing loss in left ear']\t['hearing loss']\t['left ear loss']\n",
      "TEST FAILED\t0.9999999999999998\t0.792186387316653\t0.9260162490366884\n",
      "\n",
      "['pain in right knee', 'swelling in right knee']\t['knee pain', 'swelling']\t['pain and swelling in right knee']\n",
      "TEST FAILED\t1.0\t0.7750880172033825\t0.974072042783425\n",
      "\n",
      "['shortness of breath', 'chest tightness']\t['breathlessness', 'tightness']\t['shortness of breath and chest tightness']\n",
      "TEST FAILED\t1.0\t0.8085583218814065\t0.8810306323212372\n",
      "\n",
      "['swelling of eyelids', 'redness of eyelids']\t['swelling', 'eyelid redness']\t['swelling and redness eyelids']\n",
      "TEST FAILED\t1.0\t0.8448298294323597\t0.9105959094829851\n",
      "\n",
      "['pain in both knees', 'stiffness in both knees']\t['knee pain', 'knee stiffness']\t['pain and stiffness knees']\n",
      "TEST FAILED\t1.0\t0.8862994805886395\t0.904280106395286\n",
      "\n",
      "['occasional headaches around temples']\t['occasional headaches']\t['headaches temples']\n",
      "TEST FAILED\t1.0\t0.817992908901703\t0.9175392959274749\n",
      "\n",
      "['sharp pain in left ear']\t['ear pain']\t['left ear pain']\n",
      "TEST FAILED\t1.0000000000000002\t0.8154492393229246\t0.93033803559453\n",
      "\n",
      "['persistent nasal congestion', 'sinus pressure']\t['nasal congestion', 'pressure']\t['nasal congestion pressure']\n",
      "TEST FAILED\t1.0\t0.836467028224239\t0.8524438740059637\n",
      "\n",
      "['increased thirst', 'frequent urination']\t['thirst', 'urination']\t['increased thirst frequent urination']\n",
      "TEST FAILED\t0.9999999999999999\t0.8732932392642843\t0.8937780712057067\n",
      "\n",
      "['difficulty swallowing', 'sore throat']\t['swallowing', 'throat soreness']\t['difficulty swallowing throat']\n",
      "TEST FAILED\t1.0\t0.914777003664028\t0.9195778140517433\n",
      "\n",
      "['red, watery eyes', 'nasal discharge']\t['watery eyes', 'discharge']\t['red eyes discharge']\n",
      "TEST FAILED\t1.0\t0.8037132982017499\t0.8098544126115812\n",
      "\n",
      "['bloated stomach', 'gassy stomach']\t['bloating', 'stomach']\t['bloated gassy stomach']\n",
      "TEST FAILED\t1.0000000000000002\t0.8612145761468455\t0.9352333402112961\n",
      "\n",
      "['painful burning sensation in chest']\t['burning chest pain']\t['burning sensation chest']\n",
      "TEST FAILED\t1.0000000000000002\t0.9409129031159148\t0.9498155675846762\n",
      "\n",
      "TESTS PASSED: 89\t TESTS FAILED: 23\n"
     ]
    }
   ],
   "source": [
    "p, f = test_metric(max_avg_cos_similarity, sentences, perfect, good, ok, verbose=True)\n",
    "print(f'TESTS PASSED: {p}\\t TESTS FAILED: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44495f4d",
   "metadata": {},
   "source": [
    "#### 1.1.1.b Average cosinus similarity of embeddings (greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "223c5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_idx(x):\n",
    "    k = x.argmax()\n",
    "    ncol = x.shape[1]\n",
    "    return int(k/ncol), int(k%ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def avg_cos_similarity(generated_entities, golden_entities):\n",
    "\n",
    "    generated_entities = copy.copy(generated_entities)\n",
    "    golden_entities = copy.copy(golden_entities)\n",
    "\n",
    "    min_len = min(len(golden_entities), len(generated_entities))\n",
    "    max_len = max(len(golden_entities), len(generated_entities))\n",
    "    \n",
    "    # Fill list with padding, to obtain two lists of the same size\n",
    "    for n in range(len(golden_entities), max_len):\n",
    "        golden_entities.append(None)\n",
    "\n",
    "    for n in range(len(generated_entities), max_len):  \n",
    "        generated_entities.append(None)\n",
    "        \n",
    "    # Get text embeddings for each entity\n",
    "    golden_embeddings = [get_text_embedding_using_ollama(entity) for entity in golden_entities]\n",
    "    generated_embeddings = [get_text_embedding_using_ollama(entity) for entity in generated_entities]\n",
    "\n",
    "    # Create matrix of calculated similarities between golden and generated embeddings\n",
    "    try:\n",
    "        arr = np.array([[ cosine_similarity(i,j) for i in golden_embeddings] for j in generated_embeddings])\n",
    "    except TypeError:   # if golden_embeddings or generated_embeddings is empty\n",
    "        arr = np.array([[]]) \n",
    "\n",
    "    greedy_similarity = -1\n",
    "\n",
    "    while arr.any():\n",
    "        max_i, max_j = find_max_idx(arr)\n",
    "        greedy_similarity += arr[max_i, max_j]\n",
    "        arr = np.delete(arr, max_i, axis=0)\n",
    "        arr = np.delete(arr, max_j, axis=1)\n",
    "\n",
    "    return greedy_similarity/min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2e72879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTS PASSED: 102\t TESTS FAILED: 10\n"
     ]
    }
   ],
   "source": [
    "p, f = test_metric(avg_cos_similarity, sentences, perfect, good, ok)\n",
    "print(f'TESTS PASSED: {p}\\t TESTS FAILED: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f286e",
   "metadata": {},
   "source": [
    "#### 1.1.2 Found entities measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5bded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_entities(generated_entities, golden_entities):\n",
    "    # <-1; 0) - LLM did not found all entities\n",
    "    # 0 - LLM found all entities\n",
    "    # (0; +oo) - LLM halucynated some entities\n",
    "    return len(generated_entities)/len(golden_entities) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "036cd880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTS PASSED: 57\t TESTS FAILED: 55\n"
     ]
    }
   ],
   "source": [
    "p, f = test_metric(found_entities, sentences, perfect, good, ok)\n",
    "print(f'TESTS PASSED: {p}\\t TESTS FAILED: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f75fe5e",
   "metadata": {},
   "source": [
    "## Approach 2: Measure accuracy (or other metric) of labeling task performed by LLM on each word in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748bfcdc",
   "metadata": {},
   "source": [
    "### Metric 2.1: Accuracy of generated labels\n",
    "For each generated label compare it to gold label and calculate number of correct generated labels, then divide it by a number of words in a sentence.\n",
    "\n",
    "```\n",
    "Mam przygotowany dataset w formacie: \n",
    "\t\n",
    "\t{\"word\": \"I\", \"start\": 0, \"end\": 1, \"label\": []}\n",
    "\t{\"word\": \"feel\", \"start\": 2, \"end\": 6, \"label\": []}\n",
    "\t{\"word\": \"a\", \"start\": 7, \"end\": 8, \"label\": []}\n",
    "\t{\"word\": \"bit\", \"start\": 9, \"end\": 12, \"label\": [{\"tag\": \"ADR\", \"tag number\": \"T1\"}]}\n",
    "\t{\"word\": \"drowsy\", \"start\": 13, \"end\": 19, \"label\": [{\"tag\": \"ADR\", \"tag number\": \"T1\"}]}\n",
    "\t{\"word\": \"have\", \"start\": 22, \"end\": 26, \"label\": []}\n",
    "\t\t...\n",
    "Plan działania brzmi następująco:\n",
    "- podzielenie tekstu na zdania\n",
    "- zczytanie przez LLM zdania\n",
    "- przedstawianie LLmowi kolejnych słów z tego zdania z przygotowanego datasetu z zadaniem przypisania tagów\n",
    "- sprawdzanie za pomocą accurracy czy ile tagów zostało dobrze przydzielonych\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204428f",
   "metadata": {},
   "source": [
    "#### Load benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b66c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "word_tags_dir_path = \"..\\\\data\\\\external\\\\benchmark\\\\approach_2_benchmark\"\n",
    "full_text_dir_path =  \"..\\\\data\\\\external\\\\cadec\\\\text\"\n",
    "dir_list = os.listdir(word_tags_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f0ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "word_tags_path = f'{word_tags_dir_path}\\\\{dir_list[0]}'\n",
    "full_text_path = f'{full_text_dir_path}\\\\{dir_list[0][:-6]}'\n",
    "\n",
    "with open(word_tags_path) as f:\n",
    "    word_tags = []\n",
    "    for line in f:\n",
    "        word_tags += [ast.literal_eval(line)]\n",
    "    f.close()\n",
    "\n",
    "with open(full_text_path) as f:\n",
    "    full_text = f.read()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a14774ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_llama_3_prompt(user, system=\"\", assistant=\"\"):\n",
    "    system_prompt = \"\"\n",
    "    if system:\n",
    "        system_prompt = (\n",
    "            f\"<|start_header_id|>system<|end_header_id|>\\n\\n{system}<|eot_id|>\"\n",
    "        )\n",
    "    \n",
    "    user_prompt = f\"<|start_header_id|>user<|end_header_id|>\\n\\n{user}<|eot_id|>\"\n",
    "    assistant_prompt = f\"<|start_header_id|>assistant<|end_header_id|>\\n\\n{assistant}<|eot_id|>\" if assistant else \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    \n",
    "    return f\"<|begin_of_text|>{system_prompt}{user_prompt}{assistant_prompt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aed46d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def tag_words(text, words):\n",
    "    system = \"You are an english text annotator, that have 10 years of experience in medical words tagging. \\n\"\n",
    "    system += \"Consider the following text:\\n\"\n",
    "    system += \"i had a back operation 20 years ago and my time of mobility was going from bad to worse.\"\n",
    "    system += \"Consider the following words and tags:\\n\"\n",
    "\n",
    "    words = [\n",
    "        'i', 'had', 'a', 'back', 'operation', '20', 'years', 'ago', \n",
    "        'and', 'my', 'time', 'of', 'mobility', 'was', 'going', 'from', 'bad', 'to' 'worse']\n",
    "    tags = [\n",
    "        [],[],[],[],[],[],[],[],[],[],[],[],\n",
    "        ['Symptom'], ['Symptom'], ['Symptom'], ['Symptom'], ['Symptom'], ['Symptom'], ['Symptom']\n",
    "    ]\n",
    "\n",
    "    for w,t in zip(words, tags):\n",
    "        system += \"Word: \" + w + \"\\n\"\n",
    "        system += \"Tags: \" + str(t) + \"\\n\"\n",
    "\n",
    "    \n",
    "    user = \"Based on the above example, read and analyse the following text, looking for medical entities: \" + text + \"\\n\"\n",
    "    user = \"For each word in a text, list all medical tags (remember, that there are words, that are not part of any entity)\"\n",
    "    user += \"Format the words and tags as a JSON object, i.e.\\n\"\n",
    "    user += '{\"word\" : str, \"tags\": list(str) }.\\n'\n",
    "   \n",
    "    user += \"\"\"\\\n",
    "            Make sure to only return pairs of words and tags in JSON format. \\\n",
    "            Don't give any comments. \\\n",
    "            Make sure to list all words present in a text in an original order. \\\n",
    "            \"\"\"\n",
    "    system += text\n",
    "    \n",
    "    prompt = make_llama_3_prompt(user, system)\n",
    "\n",
    "    # Generate the result from the model\n",
    "    result = ollama.generate(model='llama3.2', prompt=prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88c4db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = tag_words(full_text, word_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd52f198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateResponse(model='llama3.2', created_at='2025-11-06T11:02:06.1995517Z', done=True, done_reason='stop', total_duration=86926254900, load_duration=35265000, prompt_eval_count=459, prompt_eval_duration=110729800, eval_count=752, eval_duration=86779707400, response='{\\n    \"i\": [\"Symptom\"],\\n    \"had\": [],\\n    \"a\": [],\\n    \"back\": [],\\n    \"operation\": [],\\n    \"20\": [],\\n    \"years\": [],\\n    \"ago\": [],\\n    \"and\": [],\\n    \"my\": [],\\n    \"time\": [],\\n    \"of\": [],\\n    \"mobility\": [\"Symptom\"],\\n    \"was\": [\"Symptom\"],\\n    \"going\": [\"Symptom\"],\\n    \"from\": [\"Symptom\"],\\n    \"bad\": [\"Symptom\"],\\n    \"toworse\": [\"Symptom\"],\\n    \"i\": [\"Symptom\"],\\n    \"feel\": [],\\n    \"a\": [],\\n    \"bit\": [],\\n    \"drowsy\": [],\\n    \"and\": [],\\n    \"have\": [],\\n    \"a\": [],\\n    \"little\": [],\\n    \"blurred\": [],\\n    \"vision\", [\"Symptom\"],\\n    \"so\": [],\\n    \"far\": [],\\n    \"no\": [],\\n    \"gastric\": [\"Condition\"],\\n    \"problems\": [\"Condition\"],\\n    \"I\\'ve\": [],\\n    \"been\": [],\\n    \"on\": [],\\n    \"Arthrotec\": [\"Medication\"],\\n    \"50\": [],\\n    \"for\": [],\\n    \"over\": [],\\n    \"10\": [],\\n    \"years\": [],\\n    \"on\": [],\\n    \"and\": [],\\n    \"off\", [\"Condition\"],\\n    \"only\": [],\\n    \"taking\": [],\\n    \"it\": [],\\n    \"when\": [\"Symptom\"],\\n    \"I\": [\"Person\"],\\n    \"needed\": [],\\n    \"it\": [],\\n    \"Due\": [],\\n    \"to\": [\"Cause\"],\\n    \"my\": [],\\n    \"arthritis\": [\"Condition\"],\\n    \"getting\": [\"Action\"],\\n    \"progressively\": [\"Descriptive\"],\\n    \"worse\", [\"Symptom\"],\\n    \"to\": [\"Cause\"],\\n    \"the\": [],\\n    \"point\": [],\\n    \"where\": [\"Location\"],\\n    \"I\": [\"Person\"],\\n    \"am\": [\"State\"],\\n    \"in\": [],\\n    \"tears\": [\"Emotion\"],\\n    \"with\": [],\\n    \"the\": [],\\n    \"agony\", [\"Symptom\"],\\n    \"gp\\'s\": [\"Entity\"],\\n    \"started\": [\"Action\"],\\n    \"me\": [\"Entity\"],\\n    \"on\": [],\\n    \"75\": [],\\n    \"twice\": [\"Frequency\"],\\n    \"a\": [],\\n    \"day\": [\"Time\"],\\n    \"and\": [],\\n    \"I\": [\"Person\"],\\n    \"have\": [],\\n    \"to\": [\"Cause\"],\\n    \"take\": [\"Action\"],\\n    \"it\": [],\\n    \"every\": [\"Descriptive\"],\\n    \"day\": [\"Time\"],\\n    \"for\": [],\\n    \"the\": [],\\n    \"next\": [\"Direction\"],\\n    \"month\": [\"Time\"],\\n    \"to\": [\"Cause\"],\\n    \"see\": [\"Action\"],\\n    \"how\": [\"Question\"],\\n    \"I\": [\"Person\"],\\n    \"get\": [\"Action\"],\\n    \"on\", [\"Condition\"],\\n    \"here\": [\"Location\"],\\n    \"goes\": [\"Verb\"],\\n    \"So\": [],\\n    \"far\": [],\\n    \"its\": [\"Entity\"],\\n    \"been\": [],\\n    \"very\": [\"Descriptive\"],\\n    \"good\": [\"State\"],\\n    \"pains\": [\"Symptom\"],\\n    \"almost\": [\"Adverb\"],\\n    \"gone\", [\"Symptom\"],\\n    \"but\": [],\\n    \"feel\": [],\\n    \"a\": [],\\n    \"bit\": [],\\n    \"weird\", [\"Symptom\"],\\n    \"didn\\'t\": [\"Verb\"],\\n    \"have\": [],\\n    \"that\": [\"Entity\"],\\n    \"when\": [\"Time\"],\\n    \"on\": [],\\n    \"50\"', thinking=None, context=[128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 128000, 128006, 9125, 128007, 271, 2675, 527, 459, 30063, 1495, 37142, 859, 11, 430, 617, 220, 605, 1667, 315, 3217, 304, 6593, 4339, 79253, 13, 720, 38275, 279, 2768, 1495, 512, 72, 1047, 264, 1203, 5784, 220, 508, 1667, 4227, 323, 856, 892, 315, 31139, 574, 2133, 505, 3958, 311, 11201, 95694, 1814, 279, 2768, 4339, 323, 9681, 512, 11116, 25, 602, 198, 16309, 25, 4260, 11116, 25, 1047, 198, 16309, 25, 4260, 11116, 25, 264, 198, 16309, 25, 4260, 11116, 25, 1203, 198, 16309, 25, 4260, 11116, 25, 5784, 198, 16309, 25, 4260, 11116, 25, 220, 508, 198, 16309, 25, 4260, 11116, 25, 1667, 198, 16309, 25, 4260, 11116, 25, 4227, 198, 16309, 25, 4260, 11116, 25, 323, 198, 16309, 25, 4260, 11116, 25, 856, 198, 16309, 25, 4260, 11116, 25, 892, 198, 16309, 25, 4260, 11116, 25, 315, 198, 16309, 25, 4260, 11116, 25, 31139, 198, 16309, 25, 2570, 29012, 80797, 4532, 11116, 25, 574, 198, 16309, 25, 2570, 29012, 80797, 4532, 11116, 25, 2133, 198, 16309, 25, 2570, 29012, 80797, 4532, 11116, 25, 505, 198, 16309, 25, 2570, 29012, 80797, 4532, 11116, 25, 3958, 198, 16309, 25, 2570, 29012, 80797, 4532, 11116, 25, 16190, 11073, 198, 16309, 25, 2570, 29012, 80797, 4532, 40, 2733, 264, 2766, 294, 1849, 88, 612, 617, 264, 2697, 73500, 11376, 11, 779, 3117, 912, 89385, 5435, 627, 40, 3077, 1027, 389, 109588, 5646, 66, 220, 1135, 369, 927, 220, 605, 1667, 389, 323, 1022, 11, 1193, 4737, 433, 994, 358, 4460, 433, 627, 34160, 311, 856, 55652, 3794, 72859, 11201, 11, 311, 279, 1486, 1405, 358, 1097, 304, 24014, 449, 279, 79930, 11, 29805, 596, 3940, 757, 389, 220, 2075, 11157, 264, 1938, 323, 358, 617, 311, 1935, 433, 627, 30115, 1938, 369, 279, 1828, 2305, 311, 1518, 1268, 358, 636, 389, 11, 1618, 5900, 627, 4516, 3117, 1202, 1027, 1633, 1695, 11, 51266, 4661, 8208, 11, 719, 358, 2733, 264, 2766, 16682, 11, 3287, 956, 617, 430, 994, 389, 220, 1135, 627, 128009, 128006, 882, 128007, 271, 2520, 1855, 3492, 304, 264, 1495, 11, 1160, 682, 6593, 9681, 320, 30380, 11, 430, 1070, 527, 4339, 11, 430, 527, 539, 961, 315, 904, 5502, 8, 4152, 279, 4339, 323, 9681, 439, 264, 4823, 1665, 11, 602, 1770, 627, 5018, 1178, 1, 551, 610, 11, 330, 14412, 794, 1160, 4293, 8, 335, 627, 310, 7557, 2771, 311, 1193, 471, 13840, 315, 4339, 323, 9681, 304, 4823, 3645, 13, 1835, 4418, 956, 3041, 904, 6170, 13, 1835, 7557, 2771, 311, 1160, 682, 4339, 3118, 304, 264, 1495, 304, 459, 4113, 2015, 13, 1078, 128009, 128006, 78191, 128007, 271, 128009, 128006, 78191, 128007, 271, 517, 262, 330, 72, 794, 4482, 29012, 80797, 8257, 262, 330, 32345, 794, 10450, 262, 330, 64, 794, 10450, 262, 330, 1445, 794, 10450, 262, 330, 9446, 794, 10450, 262, 330, 508, 794, 10450, 262, 330, 42820, 794, 10450, 262, 330, 6438, 794, 10450, 262, 330, 438, 794, 10450, 262, 330, 2465, 794, 10450, 262, 330, 1712, 794, 10450, 262, 330, 1073, 794, 10450, 262, 330, 35035, 1429, 794, 4482, 29012, 80797, 8257, 262, 330, 16514, 794, 4482, 29012, 80797, 8257, 262, 330, 9738, 794, 4482, 29012, 80797, 8257, 262, 330, 1527, 794, 4482, 29012, 80797, 8257, 262, 330, 14176, 794, 4482, 29012, 80797, 8257, 262, 330, 83, 363, 11073, 794, 4482, 29012, 80797, 8257, 262, 330, 72, 794, 4482, 29012, 80797, 8257, 262, 330, 57676, 794, 10450, 262, 330, 64, 794, 10450, 262, 330, 4590, 794, 10450, 262, 330, 67, 1849, 88, 794, 10450, 262, 330, 438, 794, 10450, 262, 330, 19553, 794, 10450, 262, 330, 64, 794, 10450, 262, 330, 56492, 794, 10450, 262, 330, 2067, 8293, 794, 10450, 262, 330, 13311, 498, 4482, 29012, 80797, 8257, 262, 330, 708, 794, 10450, 262, 330, 24470, 794, 10450, 262, 330, 2201, 794, 10450, 262, 330, 6885, 496, 292, 794, 4482, 10770, 8257, 262, 330, 96440, 794, 4482, 10770, 8257, 262, 330, 40, 3077, 794, 10450, 262, 330, 82850, 794, 10450, 262, 330, 263, 794, 10450, 262, 330, 7098, 339, 5646, 66, 794, 4482, 13613, 20901, 8257, 262, 330, 1135, 794, 10450, 262, 330, 2000, 794, 10450, 262, 330, 2017, 794, 10450, 262, 330, 605, 794, 10450, 262, 330, 42820, 794, 10450, 262, 330, 263, 794, 10450, 262, 330, 438, 794, 10450, 262, 330, 1885, 498, 4482, 10770, 8257, 262, 330, 3323, 794, 10450, 262, 330, 89894, 794, 10450, 262, 330, 275, 794, 10450, 262, 330, 9493, 794, 4482, 29012, 80797, 8257, 262, 330, 40, 794, 4482, 10909, 8257, 262, 330, 41917, 794, 10450, 262, 330, 275, 794, 10450, 262, 330, 34160, 794, 10450, 262, 330, 998, 794, 4482, 62012, 8257, 262, 330, 2465, 794, 10450, 262, 330, 277, 40485, 794, 4482, 10770, 8257, 262, 330, 51210, 794, 4482, 2573, 8257, 262, 330, 14703, 3210, 794, 4482, 5001, 41419, 8257, 262, 330, 86, 11073, 498, 4482, 29012, 80797, 8257, 262, 330, 998, 794, 4482, 62012, 8257, 262, 330, 1820, 794, 10450, 262, 330, 2837, 794, 10450, 262, 330, 2940, 794, 4482, 4812, 8257, 262, 330, 40, 794, 4482, 10909, 8257, 262, 330, 309, 794, 4482, 1423, 8257, 262, 330, 258, 794, 10450, 262, 330, 668, 1590, 794, 4482, 2321, 6082, 8257, 262, 330, 4291, 794, 10450, 262, 330, 1820, 794, 10450, 262, 330, 351, 3633, 498, 4482, 29012, 80797, 8257, 262, 330, 22650, 596, 794, 4482, 3106, 8257, 262, 330, 47823, 794, 4482, 2573, 8257, 262, 330, 2727, 794, 4482, 3106, 8257, 262, 330, 263, 794, 10450, 262, 330, 2075, 794, 10450, 262, 330, 15930, 560, 794, 4482, 39714, 8257, 262, 330, 64, 794, 10450, 262, 330, 1316, 794, 4482, 1489, 8257, 262, 330, 438, 794, 10450, 262, 330, 40, 794, 4482, 10909, 8257, 262, 330, 19553, 794, 10450, 262, 330, 998, 794, 4482, 62012, 8257, 262, 330, 23609, 794, 4482, 2573, 8257, 262, 330, 275, 794, 10450, 262, 330, 30115, 794, 4482, 5001, 41419, 8257, 262, 330, 1316, 794, 4482, 1489, 8257, 262, 330, 2000, 794, 10450, 262, 330, 1820, 794, 10450, 262, 330, 3684, 794, 4482, 9452, 8257, 262, 330, 10460, 794, 4482, 1489, 8257, 262, 330, 998, 794, 4482, 62012, 8257, 262, 330, 4151, 794, 4482, 2573, 8257, 262, 330, 5269, 794, 4482, 14924, 8257, 262, 330, 40, 794, 4482, 10909, 8257, 262, 330, 456, 794, 4482, 2573, 8257, 262, 330, 263, 498, 4482, 10770, 8257, 262, 330, 6881, 794, 4482, 4812, 8257, 262, 330, 3427, 288, 794, 4482, 68046, 8257, 262, 330, 4516, 794, 10450, 262, 330, 24470, 794, 10450, 262, 330, 1220, 794, 4482, 3106, 8257, 262, 330, 82850, 794, 10450, 262, 330, 1225, 794, 4482, 5001, 41419, 8257, 262, 330, 19045, 794, 4482, 1423, 8257, 262, 330, 79, 1771, 794, 4482, 29012, 80797, 8257, 262, 330, 60301, 794, 4482, 2654, 23129, 8257, 262, 330, 46696, 498, 4482, 29012, 80797, 8257, 262, 330, 8248, 794, 10450, 262, 330, 57676, 794, 10450, 262, 330, 64, 794, 10450, 262, 330, 4590, 794, 10450, 262, 330, 906, 2668, 498, 4482, 29012, 80797, 8257, 262, 330, 97849, 956, 794, 4482, 68046, 8257, 262, 330, 19553, 794, 10450, 262, 330, 9210, 794, 4482, 3106, 8257, 262, 330, 9493, 794, 4482, 1489, 8257, 262, 330, 263, 794, 10450, 262, 330, 1135, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9cfb9",
   "metadata": {},
   "source": [
    "## 3. Other Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167cd98",
   "metadata": {},
   "source": [
    "### Precision, recall, F1-score, micro F1-scores of perfect match\n",
    "A predicted entity is considered correct only when its span and type match with the gold entity. For discontinuous entity: each span should match a span of the gold entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e58f67",
   "metadata": {},
   "source": [
    "#### Sources\n",
    "- A Span-Based Model for Joint Overlapped and Discontiunuous Named Entity Recognition\n",
    "- A Supervised Multi-Head Self-Attention Network for Nested Named Entity Recognition\n",
    "- Discontinuous Named Entity Recognition as Maximal Clique Discovery\n",
    "- Locate and Label - A Two-stage Indentifier for Nested Named Entity Recognition\n",
    "- Nested Named Entity Recognition as Latent Lexicalized Constituency Parsing\n",
    "- Neural Architectures for Named Entity Recognition\n",
    "- Rethinking Boundaries End-To-End Recognition of Discontinuous Mentions with Pionter Networks\n",
    "- Span-based Unified Named Entity Recognition Framework via Contrastive Learning\n",
    "- Unified Named Entity Recognition as Word-Word Relation Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4dbed",
   "metadata": {},
   "source": [
    "#### F1-score\n",
    "[A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition](https://github.com/foxlf823/sodner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b035af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(num, denom):\n",
    "    if denom > 0:\n",
    "        return num / denom\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def compute_f1(predicted, gold, matched):\n",
    "    precision = safe_div(matched, predicted)\n",
    "    recall = safe_div(matched, gold)\n",
    "    f1 = safe_div(2 * precision * recall, precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67244fd6",
   "metadata": {},
   "source": [
    "#### Precision, recall micro-averaged F1\n",
    "[A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition](https://github.com/foxlf823/sodner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206db917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overrides import overrides\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from allennlp.training.metrics.metric import Metric\n",
    "\n",
    "class NERMetrics(Metric):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, and micro-averaged F1 from a list of predicted and gold labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, number_of_classes: int, none_label: int=0):\n",
    "        self.number_of_classes = number_of_classes\n",
    "        self.none_label = none_label\n",
    "        self.reset()\n",
    "\n",
    "    @overrides\n",
    "    def __call__(self,\n",
    "                 predictions: torch.Tensor,\n",
    "                 gold_labels: torch.Tensor,\n",
    "                 mask: Optional[torch.Tensor] = None):\n",
    "        predictions = predictions.cpu()\n",
    "        gold_labels = gold_labels.cpu()\n",
    "        mask = mask.cpu()\n",
    "        for i in range(self.number_of_classes):\n",
    "            if i == self.none_label:\n",
    "                continue\n",
    "            self._true_positives += ((predictions==i)*(gold_labels==i)*mask.bool()).sum()\n",
    "            self._false_positives += ((predictions==i)*(gold_labels!=i)*mask.bool()).sum()\n",
    "            self._true_negatives += ((predictions!=i)*(gold_labels!=i)*mask.bool()).sum()\n",
    "            self._false_negatives += ((predictions!=i)*(gold_labels==i)*mask.bool()).sum()\n",
    "\n",
    "    @overrides\n",
    "    def get_metric(self, reset=False):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple of the following metrics based on the accumulated count statistics:\n",
    "        precision : float\n",
    "        recall : float\n",
    "        f1-measure : float\n",
    "        \"\"\"\n",
    "        precision = float(self._true_positives) / (float(self._true_positives + self._false_positives) + 1e-13)\n",
    "        recall = float(self._true_positives) / (float(self._true_positives + self._false_negatives) + 1e-13)\n",
    "        f1_measure = 2. * ((precision * recall) / (precision + recall + 1e-13))\n",
    "\n",
    "        # Reset counts if at end of epoch.\n",
    "        if reset:\n",
    "            self.reset()\n",
    "\n",
    "        return precision, recall, f1_measure\n",
    "\n",
    "    @overrides\n",
    "    def reset(self):\n",
    "        self._true_positives = 0\n",
    "        self._false_positives = 0\n",
    "        self._true_negatives = 0\n",
    "        self._false_negatives = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
