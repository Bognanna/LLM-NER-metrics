1. Implementacja
	1. Benchmark
		- [x] Wywalić sentence
		- [x] Dodać tagi, tworząc 3 rodzaje przykładów w benchmarku: test encji (tagi zawsze dobre), test tagów (encje zawsze dobre), test wszystkiego (zarówno tagi jak i encje mogą być błędne)
		- [ ] Poprawić encje: ujednolicenie zaimków (?), ujednolicenie form czasowników (?), ujednolicenie kolejności słów (?)
		- [ ] Dodać id do każdego tripla
		- [ ] Poprawić test_types
	2. Use Cases
		- [ ] Spisać Use Cases
		- [ ] Przetestować metrykę w obu wersjach na każdym z Use Casów
	3. Metryka
		- [ ] Fbeta-score zamiast F1-score
		- [ ] Ujednolicić miary tak, aby obydwie były najlepsze dla 1 i najgorsze dla 0 (albo odwrotnie)
		- [ ] Zaimplementować metrykę w jej ostatecznej formie
	4. Testy
		- [ ] Przetestować metrykę w obu wersjach na Use Cases
		- [ ] Przeprowadzić testy na benchmarku
		- [ ] Zaplanować testy na podstawie innych prac
		- [ ] Utworzyć zbiór testowy
		- [ ] Przeprowadzić testy
2. Praca
	1. Abstrakt
	2. Wstęp
	3. Opis problemu NER
	4. Opis podejść do problemu NER
	5. Opis mierzenia jakości rozwiązań 
	6. Wskazanie wad dotychczasowych metryk w odniesieniu do rozwiązań opartych o LLM
	7. Propozycja nowej metryki
	8. Przedstawienie sposobów doboru w pary
	9. Opis prac programistycznych ( ? )
	10. Opis testów wykonanych na metryce
	11. Przedstawienie wyników testów
	12. Podsumowanie
	13. Wskazanie dalszych prac
	14. Deklaracja dotycząca wykorzystania generatywnego AI przy pracach
	15. Inne:
		- [ ] Założyć projekt na overleafie
		- [ ] Dostosować templatkę
		- [ ] Rozpisać strukturę pracy
